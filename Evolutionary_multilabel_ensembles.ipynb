{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção evolutiva de conjunto de classificadores multirrótulos\n",
    "    Felipe Carneiro Machado - 14569373\n",
    "    Thales Sena de Queiroz - \n",
    "    Bruno Lima -\n",
    "\n",
    "Realizado como projeto final da disciplina SCC0911 - Computação Bionispirada\n",
    "\n",
    "Baseado no artigo: \"An evolutionary approach to build ensembles of multi-label classifiers\"\n",
    "Por: Jose M. Moyano, Eva L. Gibaja, Krzysztof J. Cios, Sebastián Ventura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "O problema da classificação multirrótulos é mais complexo que o que aparenta de imediato, visto que não deve considerar apenas as relações entre *features* mas também a relação entre rótulos.\n",
    "\n",
    "Uma das técnicas clássicas para realizar tal tarefa que identifica relações entre rótulos é o *Label Powerset* (LP), que transforma um problema multirrótulos em um problema multiclasses, onde cada classe corresponde a um elemento do *Powerset* (conjunto dos subconjuntos) do conjunto dos rótulos.\n",
    "\n",
    "Entretanto, a cardinalidade do *Powerset* de um conjunto $\\mathcal{L}=\\{\\lambda_1, \\lambda_2, ..., \\lambda_q,\\}$ é dada por\n",
    "$|\\mathcal{P}(\\mathcal{L})|=2^{q-1}$\n",
    "Ou seja, a complexidade assintótica da quantidade de rótulos é da ordem exponencial, desse modo, o método se torna inviável para problemas com quantidades muito grandes de rótulos. Os datasets abordados neste projeto possuem 12 e 8 rótulos, o que já é suficiente para procurar alternativas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposta\n",
    "Os autores do artigo no qual nos baseamos proprõem um uso alternativo do LP, em sua abordagem, um classificador é composto de $q$ classificadores multiclasse, cada um responsável por exatamente $k$ rótulos do conjunto, convertidos em problemas multiclasse pelo uso do LP.\n",
    "\n",
    "Segue a ilustração de um conjunto desse tipo, com $q=4$ e $k=2$: \n",
    "\n",
    "| |$\\lambda_1$   | $\\lambda_2$   | $\\lambda_3$   | $\\lambda_4$   |\n",
    "|------------|------------|------------|------------|------------|\n",
    "| C1  | 0  | 1  | 1  | 0  |\n",
    "| C2  | 1  | 1  | 0  | 0  |\n",
    "| C3  | 0  | 0  | 1  | 1  |\n",
    "| C4  | 0  | 1  | 0  | 1  |\n",
    "\n",
    "Onde 1 representa que o classificador está responsável por um rótulo, e 0 o contrário.\n",
    "\n",
    "Para obter um resultado final, o conjunto decide pelo \"voto\" da maioria, isto é, para cada rótulo $\\lambda_q$, sua presença ou ausência é determinada pelo resultado da maioria dos classificadores associados a este rótulo.\n",
    "\n",
    "Além disso, os autores propõem o uso de algoritmos evolutivos genéticos para encontrar o melhor conjunto de classificadores para um determinado problema. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo Evolutivo\n",
    "\n",
    "### Indivíduo\n",
    "O indivíduo é o próprio classificador, representado genomicamente por uma matrix (ou vetor) binário, de forma análoga à mostrada na seção acima. No artigo, utiliza-se como classificador multiclasses árvores de decisão construídas com o algoritmo C4.5, porém utilizaremos o algoritmo CART, para manter padrões, por ser o implementado pela biblioteca *scikit-learn*.\n",
    "\n",
    "### Função *Fitness*\n",
    "A função *Fitness* considera tanto a precisão da classificação quanto a cobertura do conjunto de rótulos, através de medidas definidas a seguir.\n",
    "\n",
    "A primeira é a FMeasure da previsão definida por\n",
    "\\begin{equation}\n",
    "FMeasure=\\frac{1}{m}\\sum_{i=0}^{m}2\\frac{\\langle Y_i, \\hat{Y_i}\\rangle}{\\langle Y_i, Y_i \\rangle + \\langle \\hat{Y_i}, \\hat{Y_i}\\rangle} \n",
    "\\end{equation}\n",
    "\n",
    "Onde $m$ é o número de observações do conjunto teste, $Y_i$ representa a i-ésima observação do conjunto de teste, e $\\hat{Y_i}$ representa a i-ésima predição do conjunto de classificadores. A FMeasure está definida no intervalo [0, 1] e busca-se maximizá-la. \n",
    "\n",
    "A segunda é o coeficiente de cobertura, que visa quantificar a homogeinidade na distribuição de rótulos por cada conjunto de classificadores. Pela maneira como o indivíduo foi definido, sempre haverá o mesmo número de rótulos avaliados em um conjunto,\n",
    "mas sua distribuição varia.\n",
    "\n",
    "O coeficiente de cobertura é definido como:\n",
    "\\begin{equation}\n",
    "C_r=\\frac{\\sigma_{individual}}{\\sigma_{worst case}}\n",
    "\\end{equation}\n",
    "\n",
    "Onde $\\sigma_{individual}$ é p desvio padrão do vetor de cobertura do indivíduo e $\\sigma_{worst case}$ é o desvio padrão no pior caso.\n",
    "\n",
    "O vetor de cobertura contém a contagem de aparições de um rótulo no conjunto. Tome como exemplo o indivíduo mostrado na seção de Introdução, seu vetor de cobertura é [1, 3, 2, 2] e o pior caso nas suas condições seria [4, 4, 0, 0].\n",
    "\n",
    "O coeficiente de cobertura também está restrito ao intervalo [0, 1] e deve ser minimizado.\n",
    "\n",
    "Por fim, a função *fitness* proposta pelo artigo é dada por:\n",
    "\\begin{equation}\n",
    "fitness=\\frac{Fmeasure + (1 - C_r)}{2}\n",
    "\\end{equation}\n",
    "\n",
    "Estando restrita ao intervalo [0, 1] e devendo ser maximizada.\n",
    "\n",
    "### *Cross-over*\n",
    "Foi utilizado o operador de *cross-over* uniforma, onde são trocadas as linhas das matrizes (genoma) entre dois indivíduos seguindo uma dada probabilidade. Como trocar linhas do genoma corresponde a trocar um classificador, todos os indivíduos gerados são válidos\n",
    "\n",
    "### Mutação baseada em correlação\n",
    "A mutação corresponde em, dentro de um classificador do indivíduo, trocar de lugar um 1 e um 0. O 1 é escolhido aleatoriamente, porém o 0 terá probabilidade de ser escolhido baseado no coeficiente $\\phi$ de correlação entre rótulos. O qual está limitado a [0, 1] com -1 singificando correlação inversa total, 0 correlação nula e 1, correlação direta total.\n",
    "\n",
    "Assim, o peso de escolha de cada 0, com posição representada por b, do classificador é dado por:\n",
    "\\begin{equation}\n",
    "w_b = \\epsilon + \\sum_{l \\in A}|\\phi_{b, l}|\n",
    "\\end{equation}\n",
    "\n",
    "Onde $A$ é conjunto de rótulos ativos no classificador e $\\phi_{b, l}$ é o coeficiente $\\phi$ de correlação entre os rótulos $b$ e $l$ e $\\epsilon$ é um pequeno valor que permite que rótulos descorrelacionados também possam ser escolhidos. O módulo é utilizado no coeficiente $\\phi$ pois busca-se apenas verficicar sua correlação, independente de sua natureza.\n",
    "\n",
    "### Fluxo do algoritmo evolutivo\n",
    "O algoritmo evolutivo usado é elitista, descartando o melhor indivíduo de uma geração apenas se houver um melhor na próxima.\n",
    "\n",
    "Também utiliza a seleção de torneio para selecionar a próxima geração, sobre a qual serão aplicados os operadores de *cross-over* e mutação.\n",
    "\n",
    "Segue abaixo o fluxo do algoritmo em pseudo-código:\n",
    "```python\n",
    "population = generate_random_population(pop_size)\n",
    "for g in max_iterations:\n",
    "    evaluate(population)\n",
    "    best_individual = best(population)\n",
    "    new_population = select_tournament(population, pop_size)\n",
    "    for indvidual in new_population:\n",
    "        cross_over(individual, choice(population))\n",
    "        mutate(individual)\n",
    "    evaluate(new_population)\n",
    "    if best_individual.fitness > best(new_population).fitness:\n",
    "        worst(new_population) = best_individual\n",
    "    population = new_population\n",
    "```\n",
    "    \n",
    "Segue abaixo a implementação do algoritmo para o dataset de plantas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./lib/python3.12/site-packages (2.1.3)\n",
      "Requirement already satisfied: pandas in ./lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in ./lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: scikit-multilearn in ./lib/python3.12/site-packages (0.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in ./lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Dependencias\n",
    "%pip install numpy pandas scikit-learn scikit-multilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas utilizadas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from random import shuffle, uniform, randint, choice, choices\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "# Para implementação foi escolhido o sklearn como framework principal e o skmultilearn para utilizar o Label Powerset\n",
    "\n",
    "# Leitura e tratamento de dados a partir do csv\n",
    "\n",
    "df = pd.read_csv(\"Plants_Dataset_Term_Frequency.tsv\", delimiter=\"\\t\")\n",
    "\n",
    "# Rotulos\n",
    "target = df[['ChloroplastProteins', 'CytoplasmProteins',       'EndoplasmicReticulumProteins', 'ExtracellProteins','GolgiApparatusProteins', 'MitochondrionProteins', 'NucleusProteins','PeroxisomeProteins', 'PlastidProteins', 'VacuoleProteins', \"CellMembraneProteins\", \"CellWallProteins\"]]    \n",
    "\n",
    "# Features\n",
    "inp = df.drop(columns=['ChloroplastProteins', 'CytoplasmProteins',\n",
    "       'EndoplasmicReticulumProteins', 'ExtracellProteins',\n",
    "       'GolgiApparatusProteins', 'MitochondrionProteins', 'NucleusProteins',\n",
    "       'PeroxisomeProteins', 'PlastidProteins', 'VacuoleProteins', \"CellMembraneProteins\", \"CellWallProteins\", \"GO_ID\"])\n",
    "\n",
    "inp = inp.to_numpy()\n",
    "target = target.to_numpy()\n",
    "\n",
    "# Separacao em teste e tein\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(inp, target, test_size=0.3, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constantes do codigo\n",
    "\n",
    "n = 12 # Numero total de labels\n",
    "k = 6 # Labels por classificador\n",
    "q = 8 # Classificadores por individuo\n",
    "pop_size = 50 # Tamanho da população\n",
    "stdvw = np.std(np.array([q] * k + [0] * (n-k))) # Desvio padrao no pior caso do vetor de cobertura\n",
    "cross_over_rate = 0.5 # Taxa de cross-over (dentro do individuo)\n",
    "cross_over_chance = 0.9 # Probabilidade de haver cross-over\n",
    "mutation_rate = 0.2 # Taxa de mutação\n",
    "max_gen = 100 # Maximo de iteracoes\n",
    "\n",
    "# Tabela hash para evitar que conjuntos que ja foram avaliados o sejam novamente\n",
    "table = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicio das funcoes do algoritmo evolutivo\n",
    "\n",
    "# Computa os valores de correlacao phi entre cada par de rotulos\n",
    "def compute_phi_matrix():\n",
    "    matrix = np.zeros((n, n), dtype=np.float64)\n",
    "    for i in range(n):\n",
    "        ni_1_ = np.sum(ytrain[:, i])\n",
    "        for j in range(i + 1, n):\n",
    "            nj_1_ = sum(ytrain[:, j])\n",
    "            nij_11 = sum((ytrain[:, j]+ytrain[:, i]) == 2)\n",
    "            nt = ytrain.shape[0]\n",
    "            matrix[i, j] = (nt * nij_11 - nj_1_ * ni_1_) / np.sqrt(ni_1_ * nj_1_ * (nt - ni_1_) * (nt - nj_1_))\n",
    "            matrix[j, i] = matrix[i, j]\n",
    "\n",
    "    return matrix\n",
    "# Acessada como variavel global      \n",
    "phi = compute_phi_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcoes para manipulacao dos conjuntos/individuos\n",
    "\n",
    "# Funcao hash para identificar cada conjunto\n",
    "def hash_ensemble(ensemble):\n",
    "    h = ()\n",
    "    for clf in ensemble:\n",
    "        clf[1].sort()\n",
    "        h += tuple(clf[1])\n",
    "    return h\n",
    "\n",
    "# Transforma uma matriz (genoma) em um conjunto de classificadores\n",
    "def matrix_to_ensemble(matrix):\n",
    "    ensemble : list[LabelPowerset]= []\n",
    "    for row in matrix:\n",
    "        l = []\n",
    "        for i in range(len(row)):\n",
    "            if row[i] == 1:\n",
    "                l.append(i)\n",
    "        ensemble.append((\n",
    "            LabelPowerset(classifier=DecisionTreeClassifier(), require_dense=[True, True])\n",
    "            .fit(xtrain, ytrain[:, l]),\n",
    "            l\n",
    "        ))\n",
    "    return ensemble\n",
    "\n",
    "# Gera uma matriz que seja um genoma valido\n",
    "def random_matrix():\n",
    "    m = [None] * q\n",
    "    for i in range(q):\n",
    "        l = [1] * k + [0] * (n - k)\n",
    "        shuffle(l)\n",
    "        m[i] = l\n",
    "    return m\n",
    "\n",
    "# Transforma um conjunto de classificadores para uma matriz/genoma\n",
    "def ensemble_to_matrix(ensemble : list[tuple[LabelPowerset, list[int]]]):\n",
    "    matrix = np.zeros((q, n))\n",
    "    for i, clf in enumerate(ensemble):\n",
    "        matrix[i, clf[1]] = 1\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcao de predicao do conjunto\n",
    "def ensemble_predict(ensemble : list[tuple[LabelPowerset, list[int]]]):\n",
    "    result = []\n",
    "    for row in xtest: # Itera pelas observacoes\n",
    "        matrix = np.ones((q, n)) * -1 # Armazena as predicoes de cada classificador\n",
    "        for i, clf in enumerate(ensemble): # Para cada classificador\n",
    "            matrix[i, clf[1]] = clf[0].predict(row.reshape(1, -1)).toarray() \n",
    "        arr = np.zeros((n,))\n",
    "        i = 0\n",
    "        # Realiza a \"votacao\" dos classificadores\n",
    "        for col in matrix.T:\n",
    "            total = 0\n",
    "            ones = 0\n",
    "            for p in col:\n",
    "                if p != -1:\n",
    "                    total += 1\n",
    "                    ones += p\n",
    "            if total == 0:\n",
    "                arr[i] = randint(0, 1)\n",
    "            else:\n",
    "                arr[i] = 1 if ones / total > 0.5 else 0\n",
    "            i += 1\n",
    "        result.append(arr)   \n",
    "    # Retorna um unico vetor de rotulos\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcoes para calculo do fitness\n",
    "\n",
    "\n",
    "# Coeficiente de cobertura\n",
    "def coverage_ratio(ensemble : list[tuple[LabelPowerset, list[int]]]):\n",
    "    arr = np.zeros((n,))\n",
    "    for clf in ensemble:\n",
    "        for i in clf[1]:\n",
    "            arr[i] += 1\n",
    "    return np.std(arr)/stdvw\n",
    "\n",
    "# Calculo da FMeasure\n",
    "def prediction_fscore(prediction : np.ndarray):\n",
    "    exf = 0\n",
    "    for i, row in enumerate(prediction):\n",
    "        exf += 2 *(row @ ytest[i]) / ((row @ row) + (ytest[i] @ ytest[i]))\n",
    "    exf = exf/ ytest.shape[0]\n",
    "    return exf\n",
    "\n",
    "# Calculo da fitness\n",
    "def fitness(ensemble, alpha = 0.7):\n",
    "    if table.get(hash_ensemble(ensemble), False): # Acessa a hash table em busca do conjunto\n",
    "        return table.get(hash_ensemble(ensemble), False)\n",
    "    prediction = ensemble_predict(ensemble)\n",
    "    fscore = prediction_fscore(prediction)\n",
    "    cr = coverage_ratio(ensemble)\n",
    "    fit = (alpha * fscore + (1 - cr) * (1-alpha)) / 2\n",
    "    table[hash_ensemble(ensemble)] = fit # Armazena o fitness na hash table\n",
    "    return fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operadores geneticos\n",
    "\n",
    "# Cross-over uniforme, retorna mas tambem realiza mudancas in-place\n",
    "def uniform_crossover(ensemble1, ensemble2):\n",
    "    for i in range(q):\n",
    "        if uniform(0, 1) < cross_over_rate:\n",
    "            temp = ensemble1[i]\n",
    "            ensemble1[i] =  ensemble2[i]\n",
    "            ensemble2[i] = temp\n",
    "    return ensemble1, ensemble2\n",
    "\n",
    "# Epsilon da equacao de pesos para mutacao\n",
    "epsilon = 0.1\n",
    "# Funcao de mutacao\n",
    "def mutate(ensemble : list[tuple[LabelPowerset, list[int]]]):\n",
    "    clf = randint(0, q - 1) # Escolhe o classificador a ser mutado\n",
    "    i1 = choice(ensemble[clf][1]) # Escolhe um rotulo ativo\n",
    "    weights = [0] * n\n",
    "    for i in range(n): # Constroi o vetor de pesos\n",
    "        if not i in ensemble[clf][1]:\n",
    "            acum = 0\n",
    "            for j in ensemble[clf][1]:\n",
    "                acum += abs(phi[i][j])                \n",
    "            weights[i] = epsilon + acum\n",
    "    swap = choices(list(range(n)), weights, k=1)[0] # Escolhe label inativa\n",
    "    # Realiza a troca\n",
    "    ensemble[clf][1].remove(i1)\n",
    "    ensemble[clf][1].append(swap)\n",
    "    # Refaz o individuo\n",
    "    return matrix_to_ensemble(ensemble_to_matrix(ensemble))\n",
    "\n",
    "# Selecao de torneio\n",
    "def tournament(pop, fits,k=2, p=1):\n",
    "    chosen = choices(list(range(pop_size)), k=k)\n",
    "    return pop[chosen[0]] if fits[chosen[0]] > fits[chosen[1]] else pop[chosen[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execucao do algoritmo evolutivo\n",
    "\n",
    "pop = [random_matrix() for _ in range(pop_size)] # Geracao aleatoria de genomas\n",
    "pop_ensembles = list(map(matrix_to_ensemble, pop)) # Gera individuos a partir do genoma\n",
    "fits = [fitness(e) for e in pop_ensembles] # Calculo de fitness\n",
    "for g in range(max_gen):\n",
    "    # Armazena o melhor individuo\n",
    "    besti = np.argmax(fits)\n",
    "    beste = deepcopy(pop_ensembles[besti])\n",
    "    bestf = fits[besti]\n",
    "    # Nova populacao selecionada a partir de torneio\n",
    "    s = [tournament(pop_ensembles, fits) for _ in range(pop_size)]\n",
    "    count = 0\n",
    "    newpop = [None] * pop_size\n",
    "    print(f\"Generation {g}: best fitness = {bestf:.4f} Mean fitness = {np.mean(fits)}\")\n",
    "    # Reconstroi a populacao atraves de cross-over e mutacao\n",
    "    while count < pop_size:\n",
    "        for i, e in enumerate(s):\n",
    "            p = uniform(0, 1)\n",
    "            if p < cross_over_rate and count < pop_size - 1 and i < pop_size - 1:\n",
    "                newpop[count], newpop[count + 1] = uniform_crossover(e, s[i + 1])\n",
    "                count += 2\n",
    "            if p < mutation_rate and count < pop_size:\n",
    "                newpop[count] = mutate(e)\n",
    "                count += 1\n",
    "            if count == pop_size:\n",
    "                break\n",
    "    # Reavaliacao da populacao\n",
    "    newfits = [fitness(e) for e in newpop]\n",
    "    newbesti = np.argmax(newfits) # Novo Melhor\n",
    "    worsti = np.argmin(newfits) # Novo pior\n",
    "    if bestf > newfits[newbesti]: # se novo melhor melhor que antigo melhor troca o antigo com o pior\n",
    "        newfits[worsti] = bestf\n",
    "        newpop[worsti] = beste\n",
    "    fits = newfits \n",
    "    pop_ensembles = newpop\n",
    "    \n",
    "bi = np.argmax(fits)\n",
    "best_ensemble = pop_ensembles[bi]\n",
    "print(\"hamming loss\")\n",
    "print(hamming_loss(ytest, ensemble_predict(best_ensemble)))\n",
    "print(\"matrix\")\n",
    "print(ensemble_to_matrix(best_ensemble)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A execução do algoritmo evolutivo é bastante demorada, assim, segue abaixo uma matriz resultado da sua execução, que pode ser facilmente transformada em classificador novamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011781609195402299\n"
     ]
    }
   ],
   "source": [
    "matrix = eval(\"\"\"list([[0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1.],\n",
    " [1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.],\n",
    " [0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0.],\n",
    " [0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0.],\n",
    " [0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.],\n",
    " [1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.],\n",
    " [0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1.],\n",
    " [0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1.]])\n",
    "\"\"\".replace(\".\", \",\"))\n",
    "ensemble = matrix_to_ensemble(matrix)\n",
    "print(hamming_loss(ytest, ensemble_predict(ensemble)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset de vírus\n",
    "Utilizaremos a mesma abordagem para o segundo dataset do trabalho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtencao dos dados\n",
    "\n",
    "df = pd.read_csv(\"Virus_Dataset_Term_Frequency.tsv\", delimiter=\"\\t\")\n",
    "\n",
    "df\n",
    "\n",
    "# # Rotulos\n",
    "target = df[[\"ViralCapsidProteins\",\"HostCellMembraneProteins\", \"HostEndoplasmicReticulumProteins\", \"HostCytoplasmProteins\", \"HostNucleusProteins\", \"SecretedProteins\"]]    \n",
    "\n",
    "# # Features\n",
    "inp = df.drop(columns=[\"ViralCapsidProteins\",\"HostCellMembraneProteins\", \"HostEndoplasmicReticulumProteins\", \"HostCytoplasmProteins\", \"HostNucleusProteins\", \"SecretedProteins\", \"GO_ID\"])\n",
    "\n",
    "inp = inp.to_numpy()\n",
    "target = target.to_numpy()\n",
    "\n",
    "# # Separacao em teste e tein\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(inp, target, test_size=0.3, train_size=0.7)\n",
    "\n",
    "\n",
    "\n",
    "# Redefinicao de constantes\n",
    "\n",
    "n = 6 # Numero total de labels\n",
    "k = 3 # Labels por classificador\n",
    "q = 6 # Classificadores por individuo\n",
    "pop_size = 50 # Tamanho da população\n",
    "stdvw = np.std(np.array([q] * k + [0] * (n-k))) # Desvio padrao no pior caso do vetor de cobertura\n",
    "cross_over_rate = 0.5 # Taxa de cross-over (dentro do individuo)\n",
    "cross_over_chance = 0.9 # Probabilidade de haver cross-over\n",
    "mutation_rate = 0.2 # Taxa de mutação\n",
    "max_gen = 100 # Maximo de iteracoes\n",
    "\n",
    "# Tabela hash para evitar que conjuntos que ja foram avaliados o sejam novamente\n",
    "table = {}\n",
    "\n",
    "# Matriz de correlacoes\n",
    "phi = compute_phi_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: best fitness = 0.4625 Mean fitness = 0.42624585093010936\n",
      "Generation 1: best fitness = 0.4625 Mean fitness = 0.42448845769327515\n",
      "Generation 2: best fitness = 0.4625 Mean fitness = 0.40596009886064005\n",
      "Generation 3: best fitness = 0.4801 Mean fitness = 0.41670509437828607\n",
      "Generation 4: best fitness = 0.4801 Mean fitness = 0.4070943899967216\n",
      "Generation 5: best fitness = 0.4801 Mean fitness = 0.41807371923733294\n",
      "Generation 6: best fitness = 0.4801 Mean fitness = 0.4293202373539922\n",
      "Generation 7: best fitness = 0.4801 Mean fitness = 0.3713881983113154\n",
      "Generation 8: best fitness = 0.4801 Mean fitness = 0.4124807647544573\n",
      "Generation 9: best fitness = 0.4801 Mean fitness = 0.3815867753169531\n",
      "Generation 10: best fitness = 0.4801 Mean fitness = 0.38271607076750724\n",
      "Generation 11: best fitness = 0.4801 Mean fitness = 0.39109554624979664\n",
      "Generation 12: best fitness = 0.4801 Mean fitness = 0.4185655381217679\n",
      "Generation 13: best fitness = 0.4801 Mean fitness = 0.41558020137974416\n",
      "Generation 14: best fitness = 0.4801 Mean fitness = 0.42559465458376927\n",
      "Generation 15: best fitness = 0.4819 Mean fitness = 0.38327936683947256\n",
      "Generation 16: best fitness = 0.4819 Mean fitness = 0.4054815432663386\n",
      "Generation 17: best fitness = 0.4819 Mean fitness = 0.4162082825438849\n",
      "Generation 18: best fitness = 0.4819 Mean fitness = 0.4077987837059194\n",
      "Generation 19: best fitness = 0.4819 Mean fitness = 0.4100223607343681\n",
      "Generation 20: best fitness = 0.4819 Mean fitness = 0.42283757829455154\n",
      "Generation 21: best fitness = 0.4819 Mean fitness = 0.42872171854977226\n",
      "Generation 22: best fitness = 0.4819 Mean fitness = 0.3722398039008246\n",
      "Generation 23: best fitness = 0.4819 Mean fitness = 0.4082475786933503\n",
      "Generation 24: best fitness = 0.4819 Mean fitness = 0.4109695782843385\n",
      "Generation 25: best fitness = 0.4819 Mean fitness = 0.39954769243931165\n",
      "Generation 26: best fitness = 0.4857 Mean fitness = 0.44249240234302073\n",
      "Generation 27: best fitness = 0.4857 Mean fitness = 0.34180934379405964\n",
      "Generation 28: best fitness = 0.4857 Mean fitness = 0.4003136685556497\n",
      "Generation 29: best fitness = 0.4857 Mean fitness = 0.42562173037463963\n",
      "Generation 30: best fitness = 0.4857 Mean fitness = 0.4176274385879054\n",
      "Generation 31: best fitness = 0.4857 Mean fitness = 0.40016069757100303\n",
      "Generation 32: best fitness = 0.4857 Mean fitness = 0.40651743574954\n",
      "Generation 33: best fitness = 0.4857 Mean fitness = 0.42219953646136477\n",
      "Generation 34: best fitness = 0.4857 Mean fitness = 0.4425663475605463\n",
      "Generation 35: best fitness = 0.4857 Mean fitness = 0.4363792974171868\n",
      "Generation 36: best fitness = 0.4857 Mean fitness = 0.4240552035022162\n",
      "Generation 37: best fitness = 0.4857 Mean fitness = 0.4257889172217981\n",
      "Generation 38: best fitness = 0.4857 Mean fitness = 0.4141416503249972\n",
      "Generation 39: best fitness = 0.4857 Mean fitness = 0.4092370655476273\n",
      "Generation 40: best fitness = 0.4857 Mean fitness = 0.402841068163416\n",
      "Generation 41: best fitness = 0.4857 Mean fitness = 0.43106933089233235\n",
      "Generation 42: best fitness = 0.4857 Mean fitness = 0.42847707856258493\n",
      "Generation 43: best fitness = 0.4857 Mean fitness = 0.4208277515044887\n",
      "Generation 44: best fitness = 0.4857 Mean fitness = 0.42598796222268837\n",
      "Generation 45: best fitness = 0.4857 Mean fitness = 0.4128582179903073\n",
      "Generation 46: best fitness = 0.4857 Mean fitness = 0.397432678938667\n",
      "Generation 47: best fitness = 0.4857 Mean fitness = 0.4048023004344026\n",
      "Generation 48: best fitness = 0.4857 Mean fitness = 0.383522915864229\n",
      "Generation 49: best fitness = 0.4857 Mean fitness = 0.38113443551500853\n",
      "Generation 50: best fitness = 0.4857 Mean fitness = 0.3885132443750235\n",
      "Generation 51: best fitness = 0.4857 Mean fitness = 0.41273264923166614\n",
      "Generation 52: best fitness = 0.4857 Mean fitness = 0.41287505734261404\n",
      "Generation 53: best fitness = 0.4857 Mean fitness = 0.37431236789331507\n",
      "Generation 54: best fitness = 0.4857 Mean fitness = 0.37712337607198315\n",
      "Generation 55: best fitness = 0.4857 Mean fitness = 0.4271303088498257\n",
      "Generation 56: best fitness = 0.4857 Mean fitness = 0.3668365331651065\n",
      "Generation 57: best fitness = 0.4857 Mean fitness = 0.3820090846546617\n",
      "Generation 58: best fitness = 0.4857 Mean fitness = 0.43094310121253293\n",
      "Generation 59: best fitness = 0.4857 Mean fitness = 0.385700963934097\n",
      "Generation 60: best fitness = 0.4857 Mean fitness = 0.3830492113140753\n",
      "Generation 61: best fitness = 0.4857 Mean fitness = 0.3965132811126214\n",
      "Generation 62: best fitness = 0.4857 Mean fitness = 0.423855461291984\n",
      "Generation 63: best fitness = 0.4857 Mean fitness = 0.425522724040653\n",
      "Generation 64: best fitness = 0.4857 Mean fitness = 0.4249854655952142\n",
      "Generation 65: best fitness = 0.4857 Mean fitness = 0.42669869020756224\n",
      "Generation 66: best fitness = 0.4857 Mean fitness = 0.41266285477190434\n",
      "Generation 67: best fitness = 0.4857 Mean fitness = 0.4307883137904141\n",
      "Generation 68: best fitness = 0.4857 Mean fitness = 0.44699487610578326\n",
      "Generation 69: best fitness = 0.4857 Mean fitness = 0.43898503126900407\n",
      "Generation 70: best fitness = 0.4857 Mean fitness = 0.40002634017794586\n",
      "Generation 71: best fitness = 0.4857 Mean fitness = 0.39883554288148965\n",
      "Generation 72: best fitness = 0.4857 Mean fitness = 0.4099187733403769\n",
      "Generation 73: best fitness = 0.4857 Mean fitness = 0.4157019452134509\n",
      "Generation 74: best fitness = 0.4857 Mean fitness = 0.4279319019055552\n",
      "Generation 75: best fitness = 0.4857 Mean fitness = 0.41643690943294787\n",
      "Generation 76: best fitness = 0.4857 Mean fitness = 0.386908570680178\n",
      "Generation 77: best fitness = 0.4883 Mean fitness = 0.37164300602007905\n",
      "Generation 78: best fitness = 0.4883 Mean fitness = 0.4152856111210831\n",
      "Generation 79: best fitness = 0.4883 Mean fitness = 0.3573085873521101\n",
      "Generation 80: best fitness = 0.4883 Mean fitness = 0.43318514170510286\n",
      "Generation 81: best fitness = 0.4883 Mean fitness = 0.4186782758298337\n",
      "Generation 82: best fitness = 0.4883 Mean fitness = 0.4295597280607325\n",
      "Generation 83: best fitness = 0.4883 Mean fitness = 0.41387340865824024\n",
      "Generation 84: best fitness = 0.4883 Mean fitness = 0.42375011748367214\n",
      "Generation 85: best fitness = 0.4883 Mean fitness = 0.411305313984559\n",
      "Generation 86: best fitness = 0.4883 Mean fitness = 0.39045122925525\n",
      "Generation 87: best fitness = 0.4883 Mean fitness = 0.4171550627630016\n",
      "Generation 88: best fitness = 0.4883 Mean fitness = 0.39175645339105086\n",
      "Generation 89: best fitness = 0.4883 Mean fitness = 0.4022683792200904\n",
      "Generation 90: best fitness = 0.4883 Mean fitness = 0.3887442163190946\n",
      "Generation 91: best fitness = 0.4883 Mean fitness = 0.400521912046414\n",
      "Generation 92: best fitness = 0.4883 Mean fitness = 0.4236466874450979\n",
      "Generation 93: best fitness = 0.4883 Mean fitness = 0.3507392223099577\n",
      "Generation 94: best fitness = 0.4883 Mean fitness = 0.409221159361432\n",
      "Generation 95: best fitness = 0.4883 Mean fitness = 0.4289596985551378\n",
      "Generation 96: best fitness = 0.4883 Mean fitness = 0.4120903854958052\n",
      "Generation 97: best fitness = 0.4883 Mean fitness = 0.4321477837046909\n",
      "Generation 98: best fitness = 0.4883 Mean fitness = 0.43286116941288355\n",
      "Generation 99: best fitness = 0.4883 Mean fitness = 0.39160001664956823\n",
      "hamming loss\n",
      "0.016129032258064516\n",
      "matrix\n",
      "[[1. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 1.]\n",
      " [1. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 1. 1.]\n",
      " [1. 1. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Execucao do algoritmo evolutivo\n",
    "\n",
    "pop = [random_matrix() for _ in range(pop_size)] # Geracao aleatoria de genomas\n",
    "pop_ensembles = list(map(matrix_to_ensemble, pop)) # Gera individuos a partir do genoma\n",
    "fits = [fitness(e) for e in pop_ensembles] # Calculo de fitness\n",
    "for g in range(max_gen):\n",
    "    # Armazena o melhor individuo\n",
    "    besti = np.argmax(fits)\n",
    "    beste = deepcopy(pop_ensembles[besti])\n",
    "    bestf = fits[besti]\n",
    "    # Nova populacao selecionada a partir de torneio\n",
    "    s = [tournament(pop_ensembles, fits) for _ in range(pop_size)]\n",
    "    count = 0\n",
    "    newpop = [None] * pop_size\n",
    "    print(f\"Generation {g}: best fitness = {bestf:.4f} Mean fitness = {np.mean(fits)}\")\n",
    "    # Reconstroi a populacao atraves de cross-over e mutacao\n",
    "    while count < pop_size:\n",
    "        for i, e in enumerate(s):\n",
    "            p = uniform(0, 1)\n",
    "            if p < cross_over_rate and count < pop_size - 1 and i < pop_size - 1:\n",
    "                newpop[count], newpop[count + 1] = uniform_crossover(e, s[i + 1])\n",
    "                count += 2\n",
    "            if p < mutation_rate and count < pop_size:\n",
    "                newpop[count] = mutate(e)\n",
    "                count += 1\n",
    "            if count == pop_size:\n",
    "                break\n",
    "    # Reavaliacao da populacao\n",
    "    newfits = [fitness(e) for e in newpop]\n",
    "    newbesti = np.argmax(newfits) # Novo Melhor\n",
    "    worsti = np.argmin(newfits) # Novo pior\n",
    "    if bestf > newfits[newbesti]: # se novo melhor melhor que antigo melhor troca o antigo com o pior\n",
    "        newfits[worsti] = bestf\n",
    "        newpop[worsti] = beste\n",
    "    fits = newfits \n",
    "    pop_ensembles = newpop\n",
    "    \n",
    "bi = np.argmax(fits)\n",
    "best_ensemble = pop_ensembles[bi]\n",
    "print(\"hamming loss\")\n",
    "print(hamming_loss(ytest, ensemble_predict(best_ensemble)))\n",
    "print(\"matrix\")\n",
    "print(ensemble_to_matrix(best_ensemble))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novamente, a execução de algoritmo é bastante lenta, assim, sua matriz resultado foi utilizada abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010752688172043012\n"
     ]
    }
   ],
   "source": [
    "matrix = eval(\"\"\"list([[1. 1. 1. 0. 0. 0.],\n",
    " [0. 0. 0. 1. 1. 1.],\n",
    " [1. 1. 0. 0. 0. 1.],\n",
    " [0. 0. 1. 0. 1. 1.],\n",
    " [1. 1. 0. 1. 0. 0.],\n",
    " [0. 0. 1. 1. 1. 0.]])\n",
    "\"\"\".replace(\".\", \",\"))\n",
    "ensemble = matrix_to_ensemble(matrix)\n",
    "print(hamming_loss(ytest, ensemble_predict(ensemble)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProjetoFinalBioinspirada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
