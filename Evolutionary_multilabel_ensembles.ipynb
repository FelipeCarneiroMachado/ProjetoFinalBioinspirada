{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção evolutiva de conjunto de classificadores multirrótulos\n",
    "    Felipe Carneiro Machado - 14569373\n",
    "    Thales Sena de Queiroz - \n",
    "    Bruno Lima -\n",
    "\n",
    "Realizado como projeto final da disciplina SCC0911 - Computação Bionispirada\n",
    "\n",
    "Baseado no artigo: \"An evolutionary approach to build ensembles of multi-label classifiers\"\n",
    "Por: Jose M. Moyano, Eva L. Gibaja, Krzysztof J. Cios, Sebastián Ventura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "O problema da classificação multirrótulos é mais complexo que o que aparenta de imediato, visto que não deve considerar apenas as relações entre *features* mas também a relação entre rótulos.\n",
    "\n",
    "Uma das técnicas clássicas para realizar tal tarefa que identifica relações entre rótulos é o *Label Powerset* (LP), que transforma um problema multirrótulos em um problema multiclasses, onde cada classe corresponde a um elemento do *Powerset* (conjunto dos subconjuntos) do conjunto dos rótulos.\n",
    "\n",
    "Entretanto, a cardinalidade do *Powerset* de um conjunto $\\mathcal{L}=\\{\\lambda_1, \\lambda_2, ..., \\lambda_q,\\}$ é dada por\n",
    "$|\\mathcal{P}(\\mathcal{L})|=2^{q-1}$\n",
    "Ou seja, a complexidade assintótica da quantidade de rótulos é da ordem exponencial, desse modo, o método se torna inviável para problemas com quantidades muito grandes de rótulos. Os datasets abordados neste projeto possuem 12 e 8 rótulos, o que já é suficiente para procurar alternativas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposta\n",
    "Os autores do artigo no qual nos baseamos proprõem um uso alternativo do LP, em sua abordagem, um classificador é composto de $q$ classificadores multiclasse, cada um responsável por exatamente $k$ rótulos do conjunto, convertidos em problemas multiclasse pelo uso do LP.\n",
    "\n",
    "Segue a ilustração de um conjunto desse tipo, com $q=4$ e $k=2$: \n",
    "\n",
    "| |$\\lambda_1$   | $\\lambda_2$   | $\\lambda_3$   | $\\lambda_4$   |\n",
    "|------------|------------|------------|------------|------------|\n",
    "| C1  | 0  | 1  | 1  | 0  |\n",
    "| C2  | 1  | 1  | 0  | 0  |\n",
    "| C3  | 0  | 0  | 1  | 1  |\n",
    "| C4  | 0  | 1  | 0  | 1  |\n",
    "\n",
    "Onde 1 representa que o classificador está responsável por um rótulo, e 0 o contrário.\n",
    "\n",
    "Para obter um resultado final, o conjunto decide pelo \"voto\" da maioria, isto é, para cada rótulo $\\lambda_q$, sua presença ou ausência é determinada pelo resultado da maioria dos classificadores associados a este rótulo.\n",
    "\n",
    "Além disso, os autores propõem o uso de algoritmos evolutivos genéticos para encontrar o melhor conjunto de classificadores para um determinado problema. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo Evolutivo\n",
    "\n",
    "### Indivíduo\n",
    "O indivíduo é o próprio classificador, representado genomicamente por uma matrix (ou vetor) binário, de forma análoga à mostrada na seção acima. No artigo, utiliza-se como classificador multiclasses árvores de decisão construídas com o algoritmo C4.5, porém utilizaremos o algoritmo CART, para manter padrões, por ser o implementado pela biblioteca *scikit-learn*.\n",
    "\n",
    "### Função *Fitness*\n",
    "A função *Fitness* considera tanto a precisão da classificação quanto a cobertura do conjunto de rótulos, através de medidas definidas a seguir.\n",
    "\n",
    "A primeira é a FMeasure da previsão definida por\n",
    "\\begin{equation}\n",
    "FMeasure=\\frac{1}{m}\\sum_{i=0}^{m}2\\frac{\\langle Y_i, \\hat{Y_i}\\rangle}{\\langle Y_i, Y_i \\rangle + \\langle \\hat{Y_i}, \\hat{Y_i}\\rangle} \n",
    "\\end{equation}\n",
    "\n",
    "Onde $m$ é o número de observações do conjunto teste, $Y_i$ representa a i-ésima observação do conjunto de teste, e $\\hat{Y_i}$ representa a i-ésima predição do conjunto de classificadores. A FMeasure está definida no intervalo [0, 1] e busca-se maximizá-la. \n",
    "\n",
    "A segunda é o coeficiente de cobertura, que visa quantificar a homogeinidade na distribuição de rótulos por cada conjunto de classificadores. Pela maneira como o indivíduo foi definido, sempre haverá o mesmo número de rótulos avaliados em um conjunto,\n",
    "mas sua distribuição varia.\n",
    "\n",
    "O coeficiente de cobertura é definido como:\n",
    "\\begin{equation}\n",
    "C_r=\\frac{\\sigma_{individual}}{\\sigma_{worst case}}\n",
    "\\end{equation}\n",
    "\n",
    "Onde $\\sigma_{individual}$ é p desvio padrão do vetor de cobertura do indivíduo e $\\sigma_{worst case}$ é o desvio padrão no pior caso.\n",
    "\n",
    "O vetor de cobertura contém a contagem de aparições de um rótulo no conjunto. Tome como exemplo o indivíduo mostrado na seção de Introdução, seu vetor de cobertura é [1, 3, 2, 2] e o pior caso nas suas condições seria [4, 4, 0, 0].\n",
    "\n",
    "O coeficiente de cobertura também está restrito ao intervalo [0, 1] e deve ser minimizado.\n",
    "\n",
    "Por fim, a função *fitness* proposta pelo artigo é dada por:\n",
    "\\begin{equation}\n",
    "fitness=\\frac{Fmeasure + (1 - C_r)}{2}\n",
    "\\end{equation}\n",
    "\n",
    "Estando restrita ao intervalo [0, 1] e devendo ser maximizada.\n",
    "\n",
    "### *Cross-over*\n",
    "Foi utilizado o operador de *cross-over* uniforma, onde são trocadas as linhas das matrizes (genoma) entre dois indivíduos seguindo uma dada probabilidade. Como trocar linhas do genoma corresponde a trocar um classificador, todos os indivíduos gerados são válidos\n",
    "\n",
    "### Mutação baseada em correlação\n",
    "A mutação corresponde em, dentro de um classificador do indivíduo, trocar de lugar um 1 e um 0. O 1 é escolhido aleatoriamente, porém o 0 terá probabilidade de ser escolhido baseado no coeficiente $\\phi$ de correlação entre rótulos. O qual está limitado a [0, 1] com -1 singificando correlação inversa total, 0 correlação nula e 1, correlação direta total.\n",
    "\n",
    "Assim, o peso de escolha de cada 0, com posição representada por b, do classificador é dado por:\n",
    "\\begin{equation}\n",
    "w_b = \\epsilon + \\sum_{l \\in A}|\\phi_{b, l}|\n",
    "\\end{equation}\n",
    "\n",
    "Onde $A$ é conjunto de rótulos ativos no classificador e $\\phi_{b, l}$ é o coeficiente $\\phi$ de correlação entre os rótulos $b$ e $l$ e $\\epsilon$ é um pequeno valor que permite que rótulos descorrelacionados também possam ser escolhidos. O módulo é utilizado no coeficiente $\\phi$ pois busca-se apenas verficicar sua correlação, independente de sua natureza.\n",
    "\n",
    "### Fluxo do algoritmo evolutivo\n",
    "O algoritmo evolutivo usado é elitista, descartando o melhor indivíduo de uma geração apenas se houver um melhor na próxima.\n",
    "\n",
    "Também utiliza a seleção de torneio para selecionar a próxima geração, sobre a qual serão aplicados os operadores de *cross-over* e mutação.\n",
    "\n",
    "Segue abaixo o fluxo do algoritmo em pseudo-código:\n",
    "```python\n",
    "population = generate_random_population(pop_size)\n",
    "for g in max_iterations:\n",
    "    evaluate(population)\n",
    "    best_individual = best(population)\n",
    "    new_population = select_tournament(population, pop_size)\n",
    "    for indvidual in new_population:\n",
    "        cross_over(individual, choice(population))\n",
    "        mutate(individual)\n",
    "    evaluate(new_population)\n",
    "    if best_individual.fitness > best(new_population).fitness:\n",
    "        worst(new_population) = best_individual\n",
    "    population = new_population\n",
    "```\n",
    "    \n",
    "Segue abaixo a implementação do algoritmo para o dataset de plantas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencias\n",
    "%pip install numpy pandas scikit-learn scikit-multilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas utilizadas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from random import shuffle, uniform, randint, choice, choices\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "# Para implementação foi escolhido o sklearn como framework principal e o skmultilearn para utilizar o Label Powerset\n",
    "\n",
    "# Leitura e tratamento de dados a partir do csv\n",
    "\n",
    "df = pd.read_csv(\"Plants_Dataset_Term_Frequency.tsv\", delimiter=\"\\t\")\n",
    "\n",
    "# Rotulos\n",
    "target = df[['ChloroplastProteins', 'CytoplasmProteins',       'EndoplasmicReticulumProteins', 'ExtracellProteins','GolgiApparatusProteins', 'MitochondrionProteins', 'NucleusProteins','PeroxisomeProteins', 'PlastidProteins', 'VacuoleProteins', \"CellMembraneProteins\", \"CellWallProteins\"]]    \n",
    "\n",
    "# Features\n",
    "inp = df.drop(columns=['ChloroplastProteins', 'CytoplasmProteins',\n",
    "       'EndoplasmicReticulumProteins', 'ExtracellProteins',\n",
    "       'GolgiApparatusProteins', 'MitochondrionProteins', 'NucleusProteins',\n",
    "       'PeroxisomeProteins', 'PlastidProteins', 'VacuoleProteins', \"CellMembraneProteins\", \"CellWallProteins\", \"GO_ID\"])\n",
    "\n",
    "inp = inp.to_numpy()\n",
    "target = target.to_numpy()\n",
    "\n",
    "# Separacao em teste e tein\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(inp, target, test_size=0.3, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constantes do codigo\n",
    "\n",
    "n = 12 # Numero total de labels\n",
    "k = 4 # Labels por classificador\n",
    "q = 10 # Classificadores por individuo\n",
    "pop_size = 100 # Tamanho da população\n",
    "stdvw = np.std(np.array([q] * k + [0] * (n-k))) # Desvio padrao no pior caso do vetore de cobertura\n",
    "cross_over_rate = 0.5 # Taxa de cross-over (dentro do individuo)\n",
    "cross_over_chance = 0.9 # Probabilidade de haver cross-over\n",
    "mutation_rate = 0.2 # Taxa de mutação\n",
    "max_gen = 200 # Maximo de iteracoes\n",
    "\n",
    "# Tabela hash para evitar que conjuntos que ja foram avaliados o sejam novamente\n",
    "table = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicio das funcoes do algoritmo evolutivo\n",
    "\n",
    "# Computa os valores de correlacao phi entre cada par de rotulos\n",
    "def compute_phi_matrix():\n",
    "    matrix = np.zeros((n, n), dtype=np.float64)\n",
    "    for i in range(n):\n",
    "        ni_1_ = np.sum(ytrain[:, i])\n",
    "        for j in range(i + 1, n):\n",
    "            nj_1_ = sum(ytrain[:, j])\n",
    "            nij_11 = sum((ytrain[:, j]+ytrain[:, i]) == 2)\n",
    "            nt = ytrain.shape[0]\n",
    "            matrix[i, j] = (nt * nij_11 - nj_1_ * ni_1_) / np.sqrt(ni_1_ * nj_1_ * (nt - ni_1_) * (nt - nj_1_))\n",
    "            matrix[j, i] = matrix[i, j]\n",
    "\n",
    "    return matrix\n",
    "# Acessada como variavel global      \n",
    "phi = compute_phi_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcoes para manipulacao dos conjuntos/individuos\n",
    "\n",
    "# Funcao hash para identificar cada conjunto\n",
    "def hash_ensemble(ensemble):\n",
    "    h = ()\n",
    "    for clf in ensemble:\n",
    "        clf[1].sort()\n",
    "        h += tuple(clf[1])\n",
    "    return h\n",
    "\n",
    "# Transforma uma matriz (genoma) em um conjunto de classificadores\n",
    "def matrix_to_ensemble(matrix):\n",
    "    ensemble : list[LabelPowerset]= []\n",
    "    for row in matrix:\n",
    "        l = []\n",
    "        for i in range(len(row)):\n",
    "            if row[i] == 1:\n",
    "                l.append(i)\n",
    "        ensemble.append((\n",
    "            LabelPowerset(classifier=DecisionTreeClassifier(), require_dense=[True, True])\n",
    "            .fit(xtrain, ytrain[:, l]),\n",
    "            l\n",
    "        ))\n",
    "    return ensemble\n",
    "\n",
    "# Gera uma matriz que seja um genoma valido\n",
    "def random_matrix():\n",
    "    m = [None] * q\n",
    "    for i in range(q):\n",
    "        l = [1] * k + [0] * (n - k)\n",
    "        shuffle(l)\n",
    "        m[i] = l\n",
    "    return m\n",
    "\n",
    "# Transforma um conjunto de classificadores para uma matriz/genoma\n",
    "def ensemble_to_matrix(ensemble : list[tuple[LabelPowerset, list[int]]]):\n",
    "    matrix = np.zeros((q, n))\n",
    "    for i, clf in enumerate(ensemble):\n",
    "        matrix[i, clf[1]] = 1\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcao de predicao do conjunto\n",
    "def ensemble_predict(ensemble : list[tuple[LabelPowerset, list[int]]]):\n",
    "    result = []\n",
    "    for row in xtest: # Itera pelas observacoes\n",
    "        matrix = np.ones((q, n)) * -1 # Armazena as predicoes de cada classificador\n",
    "        for i, clf in enumerate(ensemble): # Para cada classificador\n",
    "            matrix[i, clf[1]] = clf[0].predict(row.reshape(1, -1)).toarray() \n",
    "        arr = np.zeros((n,))\n",
    "        i = 0\n",
    "        # Realiza a \"votacao\" dos classificadores\n",
    "        for col in matrix.T:\n",
    "            total = 0\n",
    "            ones = 0\n",
    "            for p in col:\n",
    "                if p != -1:\n",
    "                    total += 1\n",
    "                    ones += p\n",
    "            if total == 0:\n",
    "                arr[i] = randint(0, 1)\n",
    "            else:\n",
    "                arr[i] = 1 if ones / total > 0.5 else 0\n",
    "            i += 1\n",
    "        result.append(arr)   \n",
    "    # Retorna um unico vetor de rotulos\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcoes para calculo do fitness\n",
    "\n",
    "\n",
    "# Coeficiente de cobertura\n",
    "def coverage_ratio(ensemble : list[tuple[LabelPowerset, list[int]]]):\n",
    "    arr = np.zeros((n,))\n",
    "    for clf in ensemble:\n",
    "        for i in clf[1]:\n",
    "            arr[i] += 1\n",
    "    return np.std(arr)/stdvw\n",
    "\n",
    "# Calculo da FMeasure\n",
    "def prediction_fscore(prediction : np.ndarray):\n",
    "    exf = 0\n",
    "    for i, row in enumerate(prediction):\n",
    "        exf += 2 *(row @ ytest[i]) / ((row @ row) + (ytest[i] @ ytest[i]))\n",
    "    exf = exf/ ytest.shape[0]\n",
    "    return exf\n",
    "\n",
    "# Calculo da fitness\n",
    "def fitness(ensemble, alpha = 0.7):\n",
    "    if table.get(hash_ensemble(ensemble), False): # Acessa a hash table em busca do conjunto\n",
    "        return table.get(hash_ensemble(ensemble), False)\n",
    "    prediction = ensemble_predict(ensemble)\n",
    "    fscore = prediction_fscore(prediction)\n",
    "    cr = coverage_ratio(ensemble)\n",
    "    fit = (alpha * fscore + (1 - cr) * (1-alpha)) / 2\n",
    "    table[hash_ensemble(ensemble)] = fit # Armazena o fitness na hash table\n",
    "    return fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operadores geneticos\n",
    "\n",
    "# Cross-over uniforme, retorna mas tambem realiza mudancas in-place\n",
    "def uniform_crossover(ensemble1, ensemble2):\n",
    "    for i in range(q):\n",
    "        if uniform(0, 1) < cross_over_rate:\n",
    "            temp = ensemble1[i]\n",
    "            ensemble1[i] =  ensemble2[i]\n",
    "            ensemble2[i] = temp\n",
    "    return ensemble1, ensemble2\n",
    "\n",
    "# Epsilon da equacao de pesos para mutacao\n",
    "epsilon = 0.1\n",
    "# Funcao de mutacao\n",
    "def mutate(ensemble : list[tuple[LabelPowerset, list[int]]]):\n",
    "    clf = randint(0, q - 1) # Escolhe o classificador a ser mutado\n",
    "    i1 = choice(ensemble[clf][1]) # Escolhe um rotulo ativo\n",
    "    weights = [0] * n\n",
    "    for i in range(n): # Constroi o vetor de pesos\n",
    "        if not i in ensemble[clf][1]:\n",
    "            acum = 0\n",
    "            for j in ensemble[clf][1]:\n",
    "                acum += abs(phi[i][j])                \n",
    "            weights[i] = epsilon + acum\n",
    "    swap = choices(list(range(n)), weights, k=1)[0] # Escolhe label inativa\n",
    "    # Realiza a troca\n",
    "    ensemble[clf][1].remove(i1)\n",
    "    ensemble[clf][1].append(swap)\n",
    "    # Refaz o individuo\n",
    "    return matrix_to_ensemble(ensemble_to_matrix(ensemble))\n",
    "\n",
    "# Selecao de torneio\n",
    "def tournament(pop, fits,k=2, p=1):\n",
    "    chosen = choices(list(range(pop_size)), k=k)\n",
    "    return pop[chosen[0]] if fits[chosen[0]] > fits[chosen[1]] else pop[chosen[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execucao do algoritmo evolutivo\n",
    "\n",
    "pop = [random_matrix() for _ in range(pop_size)] # Geracao aleatoria de genomas\n",
    "pop_ensembles = list(map(matrix_to_ensemble, pop)) # Gera individuos a partir do genoma\n",
    "fits = [fitness(e) for e in pop_ensembles] # Calculo de fitness\n",
    "for g in range(max_gen):\n",
    "    # Armazena o melhor individuo\n",
    "    besti = np.argmax(fits)\n",
    "    beste = deepcopy(pop_ensembles[besti])\n",
    "    bestf = fits[besti]\n",
    "    # Nova populacao selecionada a partir de torneio\n",
    "    s = [tournament(pop_ensembles, fits) for _ in range(pop_size)]\n",
    "    count = 0\n",
    "    newpop = [None] * pop_size\n",
    "    print(f\"Generation {g}: best fitness = {bestf:.4f} Mean fitness = {np.mean(fits)}\")\n",
    "    # Reconstroi a populacao atraves de cross-over e mutacao\n",
    "    while count < pop_size:\n",
    "        for i, e in enumerate(s):\n",
    "            p = uniform(0, 1)\n",
    "            if p < cross_over_rate and count < pop_size - 1 and i < pop_size - 1:\n",
    "                newpop[count], newpop[count + 1] = uniform_crossover(e, s[i + 1])\n",
    "                count += 2\n",
    "            if p < mutation_rate and count < pop_size:\n",
    "                newpop[count] = mutate(e)\n",
    "                count += 1\n",
    "            if count == pop_size:\n",
    "                break\n",
    "    # Reavaliacao da populacao\n",
    "    newfits = [fitness(e) for e in newpop]\n",
    "    newbesti = np.argmax(newfits) # Novo Melhor\n",
    "    worsti = np.argmin(newfits) # Novo pior\n",
    "    if bestf > newfits[newbesti]: # se novo melhor melhor que antigo melhor troca o antigo com o pior\n",
    "        newfits[worsti] = bestf\n",
    "        newpop[worsti] = beste\n",
    "    fits = newfits \n",
    "    pop_ensembles = newpop\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProjetoFinalBioinspirada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
